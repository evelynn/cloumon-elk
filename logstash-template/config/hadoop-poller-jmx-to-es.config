input {
  http_poller {
    urls => {
      namenode => "http://{namenode1}/jmx?qry=Hadoop:service=NameNode,name=NameNodeInfo"
      namenode2 => "http://{namenode2}/jmx?qry=Hadoop:service=NameNode,name=NameNodeInfo"
    }
    type => namenode_info
    request_timeout => 10
    interval => 60
    codec => "json"
  }
  http_poller {
    urls => {
      namenode => "http://{namenode1}/jmx?qry=Hadoop:service=NameNode,name=NameNodeStatus"
      namenode2 => "http://{namenode2}/jmx?qry=Hadoop:service=NameNode,name=NameNodeStatus"
    }
    request_timeout => 10
    interval => 60
    codec => "json"
	  type => namenode_status
  }
}

filter {
  if [type] == "namenode_info" {
    throttle {
      before_count => -1
      after_count => 1
      period => 30
      key => "NameNodeInfo"
      add_tag => "throttled"
    }
    if "throttled" in [tags] {
      drop { }
    }
  }

  ruby {
    init => "require 'json'
      @livenode_metrics = ['lastContact', 'adminState']
      @deadnode_metrics = ['lastContact', 'decommissioned']
      @number_classes = [Fixnum, Float]

      def filter(event, &block)
        namenode_info_filter event, &block if event['type'] == 'namenode_info'
        namenode_status_filter event, &block if event['type'] == 'namenode_status'
      end

      def namenode_status_filter(event, &block)
        event['host'] = event['beans'][0]['HostAndPort']
        event['name'] = '%s.State' % event['type']
        event['val_str'] = event['beans'][0]['State']
        event.remove('beans')
        event.remove('type')
      end 

      def namenode_info_filter(event, &block)
        begin
          live_nodes = JSON.parse(event['beans'][0]['LiveNodes'])
          dead_nodes = JSON.parse(event['beans'][0]['DeadNodes'])

          live_nodes.each do |key, value|
            @livenode_metrics.each do |metric_key|
              data = {'@timestamp' => event['@timestamp'], 'host' => key}
              data['name'] = '%s.live.%s' % [event['type'], metric_key]

              if @number_classes.include? value[metric_key].class
                data['val_double'] = value[metric_key]
              else
                data['val_str'] = value[metric_key]
              end

              e = LogStash::Event.new(data)

              yield e
            end # end livenode_metric each
          end # end live_nodes each

          dead_nodes.each do |key, value|
            @deadnode_metrics.each do |metric_key|
              data = {'@timestamp' => event['@timestamp'], 'host' => key}
              data['name'] = '%s.dead.%s' % [event['type'], metric_key]

              if @number_classes.include? value[metric_key].class
                data['val_double'] = value[metric_key]
              else
                data['val_str'] = value[metric_key]
              end

              e = LogStash::Event.new(data)

              yield e
            end # end deadnode_metric each
          end # end dead_nodes each

          event.cancel
        rescue Exception => e
          @logger.error('Ruby exception occured: #{e}')
          event.tag('_rubyexception')
        end # end begin
      end # end def
    
    "
    code => "
      puts 'monkey patching for filter function'
    "
  }

}

output {
	elasticsearch_java {
    network_host => "0.0.0.0"
		protocol => "transport"
		cluster => "cloumon-elk"
		hosts => {es_hosts}
    index => "{cluster_name}-hadoop-jmx-metrics-%{+YYYY.MM.dd}"
	}
}
